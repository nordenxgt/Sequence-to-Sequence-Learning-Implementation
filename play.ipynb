{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "\n",
    "import html\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 4488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(rows):\n",
    "    return {\n",
    "        \"en\": [text.split(\"\\t\")[0] for text in rows[\"text\"]],\n",
    "        \"fr\": [text.split(\"\\t\")[1] for text in rows[\"text\"]],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "def clean_text(batch):\n",
    "    return {k: [unidecode(s) for s in v] for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path: str, data_files: str) -> datasets:\n",
    "    ds = datasets.load_dataset(path=path, data_files=data_files)\n",
    "    ds = ds.map(split_texts, batched=True).remove_columns(\"text\")\n",
    "    ds = ds.map(clean_text, batched=True)\n",
    "    ds = ds[\"train\"].train_test_split(train_size=0.8, seed=seed)\n",
    "    tvt_ds = ds[\"train\"].train_test_split(train_size=0.8, seed=seed)\n",
    "    tvt_ds[\"validation\"] = tvt_ds.pop(\"test\")\n",
    "    tvt_ds[\"test\"] = ds[\"test\"]\n",
    "    return tvt_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(path=\"./data\", data_files=\"en-fr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': ['Could you speak more slowly?',\n",
       "  \"It makes me really happy that you're here.\",\n",
       "  'We were right.',\n",
       "  'They fight like cat and dog.',\n",
       "  \"I'm not worried about losing my job.\"],\n",
       " 'fr': ['Pouvez-vous parler plus lentement ?',\n",
       "  'Je me rejouis vraiment que tu sois ici.',\n",
       "  'Nous eumes raison.',\n",
       "  'Ils se disputent comme chien et chat.',\n",
       "  'Je ne suis pas inquiet de perdre mon emploi.']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_news_sm\n",
    "# !pip uninstall en-core-news-sm\n",
    "\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !pip uninstall fr-core-news-sm\n",
    "\n",
    "# !pip uninstall de-core-news-sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "fr_nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ds(data, en_nlp, fr_nlp, max_length, sos_token, eos_token):\n",
    "    return {\n",
    "        \"en_tokens\": [sos_token] + [token.text.lower() for token in en_nlp.tokenizer(data[\"en\"])][:max_length] + [eos_token], \n",
    "        \"fr_tokens\": [sos_token] + [token.text.lower() for token in fr_nlp.tokenizer(data[\"fr\"])][:max_length] + [eos_token]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "max_length = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"fr_nlp\": fr_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_ds, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_ds, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_ds, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")\n",
    "\n",
    "fr_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"fr_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', '.', 'i', 'you', 'to', 'the', '?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', '.', 'je', 'a', 'de', '?', 'pas']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == fr_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == fr_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "fr_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[\"The\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 137, 546, 1007, 3479]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_vocab(vocab: str, en_vocab, fr_vocab):\n",
    "    return {\n",
    "        \"en_ids\": en_vocab.lookup_indices(vocab[\"en_tokens\"]),\n",
    "        \"fr_ids\": fr_vocab.lookup_indices(vocab[\"fr_tokens\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_kwargs = {\n",
    "    \"en_vocab\": en_vocab, \n",
    "    \"fr_vocab\": fr_vocab\n",
    "}\n",
    "train_data = train_data.map(numericalize_vocab, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_vocab, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_vocab, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Could you speak more slowly?',\n",
       " 'fr': 'Pouvez-vous parler plus lentement ?',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'could',\n",
       "  'you',\n",
       "  'speak',\n",
       "  'more',\n",
       "  'slowly',\n",
       "  '?',\n",
       "  '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'pouvez',\n",
       "  '-vous',\n",
       "  'parler',\n",
       "  'plus',\n",
       "  'lentement',\n",
       "  '?',\n",
       "  '<eos>'],\n",
       " 'en_ids': [2, 75, 6, 201, 95, 1045, 9, 3],\n",
       " 'fr_ids': [2, 151, 34, 123, 47, 1143, 8, 3]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'could', 'you', 'speak', 'more', 'slowly', '?', '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(train_data[0][\"en_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"torch\"\n",
    "columns = [\"en_ids\", \"fr_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(type=datatype, columns=columns, output_all_columns=True)\n",
    "valid_data = valid_data.with_format(type=datatype, columns=columns, output_all_columns=True)\n",
    "test_data = test_data.with_format(type=datatype, columns=columns, output_all_columns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   2,   75,    6,  201,   95, 1045,    9,    3]),\n",
       " 'fr_ids': tensor([   2,  151,   34,  123,   47, 1143,    8,    3]),\n",
       " 'en': 'Could you speak more slowly?',\n",
       " 'fr': 'Pouvez-vous parler plus lentement ?',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'could',\n",
       "  'you',\n",
       "  'speak',\n",
       "  'more',\n",
       "  'slowly',\n",
       "  '?',\n",
       "  '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'pouvez',\n",
       "  '-vous',\n",
       "  'parler',\n",
       "  'plus',\n",
       "  'lentement',\n",
       "  '?',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        return {\n",
    "            \"en_ids\": nn.utils.rnn.pad_sequence(\n",
    "                [vocab[\"en_ids\"] for vocab in batch], \n",
    "                padding_value=pad_index,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            \"fr_ids\": nn.utils.rnn.pad_sequence(\n",
    "                [vocab[\"fr_ids\"] for vocab in batch], \n",
    "                padding_value=pad_index,\n",
    "                batch_first=True\n",
    "            )\n",
    "        }\n",
    "    return collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_dataloader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_dataloader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab: int, embedding_dim: int, hidden_dim: int, num_layers: int, dropout: int):\n",
    "        super().__init__()\n",
    "        self.input_vocab = input_vocab\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_vocab, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        _, (hidden, cell) = self.lstm(embedded) \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_vocab: int, embedding_dim: int, hidden_dim: int, num_layers: int, dropout: int):\n",
    "        super().__init__()\n",
    "        self.output_vocab = output_vocab\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(output_vocab, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_vocab)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor, hidden: torch.Tensor, cell: torch.Tensor) -> torch.Tensor:\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell)) \n",
    "        output = self.fc(output.squeeze(1))\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(len(en_vocab), embedding_dim=256, hidden_dim=5, num_layers=4, dropout=0.1)\n",
    "dec = Decoder(output_vocab=len(fr_vocab), embedding_dim=256, hidden_dim=5, num_layers=4, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        assert encoder.hidden_dim == decoder.hidden_dim\n",
    "        assert encoder.num_layers == decoder.num_layers\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src: torch.Tensor, target: torch.Tensor, tf_ratio: float) -> torch.Tensor:\n",
    "        target_length = target.shape[1]\n",
    "\n",
    "        outputs = torch.zeros(target.shape[0], target_length, self.decoder.output_vocab).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = target[:, 0]\n",
    "\n",
    "        for t in range(1, target_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            input = target[:, t] if random.random() < tf_ratio else output.argmax(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Seq2Seq(encoder=enc, decoder=dec, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_dataloader:\n",
    "    src = x[\"en_ids\"]\n",
    "    trg = x[\"fr_ids\"]\n",
    "    model(src, trg, 0.6)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
